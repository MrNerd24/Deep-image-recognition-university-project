{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA20001 Deep Learning - Group Project\n",
    "## Image project\n",
    "\n",
    "21/05/2020\n",
    "- Second test of testing [resnext50_32x4d](https://pytorch.org/docs/stable/torchvision/models.html#id27) pretrained transfer learning model with hidden fully-connected layer with 256 nodes.\n",
    "  - this time with more epochs and fixed model selection criteria (f1)\n",
    "- Data preprocessing includes: (same preprocessing steps as exp_transfer_learning_2.ipynb)\n",
    "  - shuffle\n",
    "  - split: train=17k, val=1.5k, test=1.5k\n",
    "  - data augmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# automatically reload dependencies and repository content so that kernel need not be restarted\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dependencies and select correct device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import train_model\n",
    "import eval_model\n",
    "import utils\n",
    "from image_dataset import ImageDataset\n",
    "from data_augmentation import DataAugmentation\n",
    "\n",
    "import time\n",
    "import torch\n",
    "from torchvision import models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n"
     ]
    }
   ],
   "source": [
    "device = None\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Using GPU\")\n",
    "    device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    print(\"Using CPU\")\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define datasets\n",
    "\n",
    "- shuffle\n",
    "- train: 17k\n",
    "- valid: 1.5k\n",
    "- test: 1.5k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving test dataset temporarily so test can be performed after restarting kernel.\n",
      "# Train: 17000\n",
      "# Valid: 1500\n",
      "# Test: 1500\n"
     ]
    }
   ],
   "source": [
    "mapping_file = \"file_to_labels_table.csv\"\n",
    "df = pd.read_csv(mapping_file)\n",
    "train_idx, val_idx = utils.get_train_val_indexes(df, 0.85, shuffle=True)\n",
    "val_test_split_idx = int(val_idx.shape[0]*.5)\n",
    "test_idx = val_idx[:val_test_split_idx]\n",
    "val_idx = val_idx[val_test_split_idx:]\n",
    "\n",
    "dataAugmentation = DataAugmentation()\n",
    "trainDataset = ImageDataset(train_idx, dataAugmentation=dataAugmentation)\n",
    "valDataset = ImageDataset(val_idx)\n",
    "testDataset = ImageDataset(test_idx)\n",
    "\n",
    "print(\"Saving test dataset temporarily so test can be performed after restarting kernel.\")\n",
    "utils.save_pickle(testDataset, \"tmp_test_data_exp_transfer_learning_4.pkl\")\n",
    "print(\"# Train:\", len(trainDataset))\n",
    "print(\"# Valid:\", len(valDataset))\n",
    "print(\"# Test:\", len(testDataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model architecture\n",
    "\n",
    "The initial transfer learning implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "preTrainedModel = models.resnext50_32x4d(pretrained=True)\n",
    "\n",
    "for param in preTrainedModel.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "num_ftrs = preTrainedModel.fc.in_features\n",
    "num_classes = 14\n",
    "\n",
    "preTrainedModel.fc = torch.nn.Sequential(\n",
    "    torch.nn.Linear(num_ftrs, 256),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(256, num_classes),\n",
    "    torch.nn.Sigmoid()\n",
    ")\n",
    "\n",
    "model = preTrainedModel.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define test case\n",
    "\n",
    "Hyperparam search could be defined here. No hyperparam searches in this notebook as purpose of this test is to test the effect of data preprocessing technique on initial transfer learning model architecture and see how longer run on epochs affect loss.\n",
    "\n",
    "**Test objective**:\n",
    "\n",
    "- Testing second implementation of [resnext50_32x4d](https://pytorch.org/docs/stable/torchvision/models.html#id27) implementation of pretrained transfer learning models\n",
    "  - New addition: hidden fully-connected layer with 256 nodes\n",
    "- Data preprocessing includes data augmentation, shuffle and split train=17k, val=1.5k, test=1.5k\n",
    "- Data augmentation IS applied\n",
    "\n",
    "**Training results**:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/10\n",
      "----------\n",
      "Validating...\n",
      "\n",
      "Progress: 100%\n",
      "\n",
      "Loss: 0.6826 Accuracy: 0.5869\n",
      "Precision: 0.0736 Recall: 0.4142\n",
      "F1: 0.1251 Duration: 1m 12s\n",
      "\n",
      "Epoch 1/10\n",
      "----------\n",
      "Training...\n",
      "\n",
      "Progress: 100%\n",
      "\n",
      "Loss: 0.1553 Accuracy: 0.9434\n",
      "Precision: 0.6888 Recall: 0.4012\n",
      "F1: 0.5070 Duration: 20m 0s\n",
      "\n",
      "Validating...\n",
      "\n",
      "Progress: 100%\n",
      "\n",
      "Loss: 0.1362 Accuracy: 0.9470\n",
      "Precision: 0.6002 Recall: 0.7702\n",
      "F1: 0.6747 Duration: 1m 13s\n",
      "\n",
      "Epoch 2/10\n",
      "----------\n",
      "Training...\n",
      "\n",
      "Progress: 100%\n",
      "\n",
      "Loss: 0.1371 Accuracy: 0.9489\n",
      "Precision: 0.7245 Recall: 0.4767\n",
      "F1: 0.5751 Duration: 19m 34s\n",
      "\n",
      "Validating...\n",
      "\n",
      "Progress: 100%\n",
      "\n",
      "Loss: 0.1197 Accuracy: 0.9567\n",
      "Precision: 0.8316 Recall: 0.4916\n",
      "F1: 0.6180 Duration: 1m 14s\n",
      "\n",
      "Epoch 3/10\n",
      "----------\n",
      "Training...\n",
      "\n",
      "Progress: 100%\n",
      "\n",
      "Loss: 0.1322 Accuracy: 0.9510\n",
      "Precision: 0.7433 Recall: 0.4960\n",
      "F1: 0.5950 Duration: 19m 59s\n",
      "\n",
      "Validating...\n",
      "\n",
      "Progress: 100%\n",
      "\n",
      "Loss: 0.1095 Accuracy: 0.9591\n",
      "Precision: 0.7099 Recall: 0.7208\n",
      "F1: 0.7153 Duration: 1m 14s\n",
      "\n",
      "Epoch 4/10\n",
      "----------\n",
      "Training...\n",
      "\n",
      "Progress: 100%\n",
      "\n",
      "Loss: 0.1286 Accuracy: 0.9523\n",
      "Precision: 0.7535 Recall: 0.5082\n",
      "F1: 0.6070 Duration: 19m 51s\n",
      "\n",
      "Validating...\n",
      "\n",
      "Progress: 100%\n",
      "\n",
      "Loss: 0.1010 Accuracy: 0.9635\n",
      "Precision: 0.8012 Recall: 0.6486\n",
      "F1: 0.7169 Duration: 1m 19s\n",
      "\n",
      "Epoch 5/10\n",
      "----------\n",
      "Training...\n",
      "\n",
      "Progress: 100%\n",
      "\n",
      "Loss: 0.1280 Accuracy: 0.9526\n",
      "Precision: 0.7581 Recall: 0.5100\n",
      "F1: 0.6098 Duration: 19m 55s\n",
      "\n",
      "Validating...\n",
      "\n",
      "Progress: 100%\n",
      "\n",
      "Loss: 0.1083 Accuracy: 0.9600\n",
      "Precision: 0.7370 Recall: 0.6814\n",
      "F1: 0.7081 Duration: 1m 7s\n",
      "\n",
      "Epoch 6/10\n",
      "----------\n",
      "Training...\n",
      "\n",
      "Progress: 100%\n",
      "\n",
      "Loss: 0.1276 Accuracy: 0.9527\n",
      "Precision: 0.7556 Recall: 0.5141\n",
      "F1: 0.6119 Duration: 19m 55s\n",
      "\n",
      "Validating...\n",
      "\n",
      "Progress: 100%\n",
      "\n",
      "Loss: 0.1065 Accuracy: 0.9612\n",
      "Precision: 0.7363 Recall: 0.7108\n",
      "F1: 0.7233 Duration: 1m 13s\n",
      "\n",
      "Epoch 7/10\n",
      "----------\n",
      "Training...\n",
      "\n",
      "Progress: 100%\n",
      "\n",
      "Loss: 0.1261 Accuracy: 0.9532\n",
      "Precision: 0.7597 Recall: 0.5186\n",
      "F1: 0.6164 Duration: 20m 2s\n",
      "\n",
      "Validating...\n",
      "\n",
      "Progress: 100%\n",
      "\n",
      "Loss: 0.1046 Accuracy: 0.9612\n",
      "Precision: 0.7484 Recall: 0.6874\n",
      "F1: 0.7166 Duration: 1m 20s\n",
      "\n",
      "Epoch 8/10\n",
      "----------\n",
      "Training...\n",
      "\n",
      "Progress: 100%\n",
      "\n",
      "Loss: 0.1261 Accuracy: 0.9530\n",
      "Precision: 0.7588 Recall: 0.5171\n",
      "F1: 0.6151 Duration: 19m 57s\n",
      "\n",
      "Validating...\n",
      "\n",
      "Progress: 100%\n",
      "\n",
      "Loss: 0.1115 Accuracy: 0.9590\n",
      "Precision: 0.7950 Recall: 0.5725\n",
      "F1: 0.6656 Duration: 1m 17s\n",
      "\n",
      "Epoch 9/10\n",
      "----------\n",
      "Training...\n",
      "\n",
      "Progress: 100%\n",
      "\n",
      "Loss: 0.1232 Accuracy: 0.9546\n",
      "Precision: 0.7674 Recall: 0.5370\n",
      "F1: 0.6318 Duration: 20m 39s\n",
      "\n",
      "Validating...\n",
      "\n",
      "Progress: 100%\n",
      "\n",
      "Loss: 0.1059 Accuracy: 0.9627\n",
      "Precision: 0.7902 Recall: 0.6493\n",
      "F1: 0.7129 Duration: 1m 20s\n",
      "\n",
      "Epoch 10/10\n",
      "----------\n",
      "Training...\n",
      "\n",
      "Progress: 100%\n",
      "\n",
      "Loss: 0.1233 Accuracy: 0.9542\n",
      "Precision: 0.7671 Recall: 0.5291\n",
      "F1: 0.6262 Duration: 20m 41s\n",
      "\n",
      "Validating...\n",
      "\n",
      "Progress: 100%\n",
      "\n",
      "Loss: 0.1100 Accuracy: 0.9616\n",
      "Precision: 0.7578 Recall: 0.6774\n",
      "F1: 0.7153 Duration: 1m 20s\n",
      "\n",
      "Training complete in 214m 22s\n",
      "Best f1: 0.723317\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "\n",
    "model, logs = train_model.train_model(\n",
    "    model,\n",
    "    trainDataset,\n",
    "    valDataset,\n",
    "    device,\n",
    "    numberOfEpochs=n_epochs,\n",
    "    returnLogs=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model and logs\n",
    "\n",
    "It might be useful to save your model if you want to continue your work later, or use it for inference later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(logs[\"val\"]).to_csv(\"exp_transfer_learning_4_2_val_logs.csv\", index=False)\n",
    "pd.DataFrame(logs[\"train\"]).to_csv(\"exp_transfer_learning_4_2_train_logs.csv\", index=False)\n",
    "torch.save(model, 'exp_transfer_learning_4_2_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model\n",
    "\n",
    "- Load model back from state_dict and perform test on testing set\n",
    "- Load test-set\n",
    "- Load training time logs of performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"exp_transfer_learning_4_2_model.pkl\")\n",
    "testDataset = utils.load_pickle(\"tmp_test_data_exp_transfer_learning_4.pkl\")\n",
    "val_logs = pd.read_csv(\"exp_transfer_learning_4_2_val_logs.csv\")\n",
    "train_logs = pd.read_csv(\"exp_transfer_learning_4_2_train_logs.csv\")\n",
    "y_hats, y_trues = eval_model.test_model(model, testDataset, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation set performance during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epoch': [0, 1, 2, 3, 4],\n",
       " 'accuracy': [tensor(0.9579, dtype=torch.float64),\n",
       "  tensor(0.9565, dtype=torch.float64),\n",
       "  tensor(0.9581, dtype=torch.float64),\n",
       "  tensor(0.9597, dtype=torch.float64),\n",
       "  tensor(0.9601, dtype=torch.float64)],\n",
       " 'loss': [0.1101102386471771,\n",
       "  0.11380755911554609,\n",
       "  0.10892651088748659,\n",
       "  0.10757335066511517,\n",
       "  0.10641117515166601]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing set performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing set results.\n",
      " Accuracy\t0.959\n",
      " Precision\t0.745\n",
      " Recall \t0.688\n",
      " F1-score\t0.715\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing set results.\")\n",
    "print(f\" Accuracy\\t{round(eval_model.get_metric(y_trues, y_hats, 'accuracy'), 3)}\")\n",
    "print(f\" Precision\\t{round(eval_model.get_metric(y_trues, y_hats, 'precision'), 3)}\")\n",
    "print(f\" Recall \\t{round(eval_model.get_metric(y_trues, y_hats, 'recall'), 3)}\")\n",
    "print(f\" F1-score\\t{round(eval_model.get_metric(y_trues, y_hats, 'f1'), 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra analysis\n",
    "\n",
    "How many positives and negatives has been predicted.\n",
    "\n",
    "Tuples like: **(label, count)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 19592), (1, 1408)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(*np.unique(y_hats, return_counts=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download test set\n",
    "\n",
    "The testset will be made available during the last week before the deadline and can be downloaded in the same way as the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict for test set\n",
    "\n",
    "You should return your predictions for the test set in a plain text file.  The text file contains one row for each test set image.  Each row contains a binary prediction for each label (separated by a single space), 1 if it's present in the image, and 0 if not. The order of the labels is as follows (alphabetic order of the label names):\n",
    "\n",
    "    baby bird car clouds dog female flower male night people portrait river sea tree\n",
    "\n",
    "An example row could like like this if your system predicts the presense of a bird and clouds:\n",
    "\n",
    "    0 1 0 1 0 0 0 0 0 0 0 0 0 0\n",
    "    \n",
    "The order of the rows should be according to the numeric order of the image numbers.  In the test set, this means that the first row refers to image `im20001.jpg`, the second to `im20002.jpg`, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have the prediction output matrix prepared in `y` you can use the following function to save it to a text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('results.txt', y, fmt='%d')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
