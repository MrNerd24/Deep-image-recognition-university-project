{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA20001 Deep Learning - Group Project\n",
    "## Image project\n",
    "\n",
    "- Testing [resnext101_32x8d](https://pytorch.org/docs/stable/torchvision/models.html#id27) implementation of pretrained transfer learning models\n",
    "- Data preprocessing includes data augmentation, shuffle and split train=17k, val=1.5k, test=1.5k\n",
    "- Data augmentation IS applied\n",
    "- No data balancing applied\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# automatically reload dependencies and repository content so that kernel need not be restarted\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dependencies and select correct device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import train_model\n",
    "import eval_model\n",
    "import utils\n",
    "from image_dataset import ImageDataset\n",
    "from data_augmentation import DataAugmentation\n",
    "\n",
    "import time\n",
    "import torch\n",
    "from torchvision import models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n"
     ]
    }
   ],
   "source": [
    "device = None\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Using GPU\")\n",
    "    device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    print(\"Using CPU\")\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define datasets\n",
    "\n",
    "- shuffle\n",
    "- train: 17k\n",
    "- valid: 1.5k\n",
    "- test: 1.5k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving test dataset temporarily so test can be performed after restarting kernel.\n",
      "# Train: 17000\n",
      "# Valid: 1500\n",
      "# Test: 1500\n"
     ]
    }
   ],
   "source": [
    "mapping_file = \"file_to_labels_table.csv\"\n",
    "df = pd.read_csv(mapping_file)\n",
    "train_idx, val_idx = utils.get_train_val_indexes(df, 0.85, shuffle=True)\n",
    "val_test_split_idx = int(val_idx.shape[0]*.5)\n",
    "test_idx = val_idx[:val_test_split_idx]\n",
    "val_idx = val_idx[val_test_split_idx:]\n",
    "\n",
    "dataAugmentation = DataAugmentation()\n",
    "trainDataset = ImageDataset(train_idx, dataAugmentation=dataAugmentation)\n",
    "valDataset = ImageDataset(val_idx)\n",
    "testDataset = ImageDataset(test_idx)\n",
    "\n",
    "print(\"Saving test dataset temporarily so test can be performed after restarting kernel.\")\n",
    "utils.save_pickle(testDataset, \"tmp_test_data_exp_transfer_learning_5.pkl\")\n",
    "print(\"# Train:\", len(trainDataset))\n",
    "print(\"# Valid:\", len(valDataset))\n",
    "print(\"# Test:\", len(testDataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model architecture\n",
    "\n",
    "The initial transfer learning implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "preTrainedModel = models.resnext101_32x8d(pretrained=True)\n",
    "\n",
    "for param in preTrainedModel.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "num_ftrs = preTrainedModel.fc.in_features\n",
    "num_classes = 14\n",
    "\n",
    "preTrainedModel.fc = torch.nn.Sequential(\n",
    "    torch.nn.Linear(num_ftrs, num_classes),\n",
    "    torch.nn.Sigmoid()\n",
    ")\n",
    "\n",
    "model = preTrainedModel.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define test case\n",
    "\n",
    "Hyperparam search could be defined here. No hyperparam searches in this notebook as purpose of this test is to test the effect of data preprocessing technique on initial transfer learning model architecture and see how longer run on epochs affect loss.\n",
    "\n",
    "**Test objective**:\n",
    "\n",
    "- Testing [resnext101_32x8d](https://pytorch.org/docs/stable/torchvision/models.html#id27) implementation of pretrained transfer learning model\n",
    "- Data preprocessing includes \n",
    "  - data augmentation, \n",
    "  - shuffle \n",
    "  - split train=17k, val=1.5k, test=1.5k\n",
    "\n",
    "\n",
    "**Training results**:\n",
    "\n",
    "- Best validation results:\n",
    " - Loss: 0.1113 Accuracy: 0.9619\n",
    " - Precision: 0.7223 Recall: 0.7258\n",
    " - F1: 0.7241 Duration: 2m 3s\n",
    "- Testing set results.\n",
    " - Accuracy 0.963\n",
    " - Precision 0.745\n",
    " - Recall 0.742\n",
    " - F1-score 0.743"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/6\n",
      "----------\n",
      "Validating...\n",
      "\n",
      "Progress: 100%\n",
      "\n",
      "Loss: 0.6959 Accuracy: 0.5098\n",
      "Precision: 0.0681 Recall: 0.4414\n",
      "F1: 0.1181 Duration: 3m 7s\n",
      "\n",
      "Epoch 1/6\n",
      "----------\n",
      "Training...\n",
      "\n",
      "Progress: 100%\n",
      "\n",
      "Loss: 0.1407 Accuracy: 0.9500\n",
      "Precision: 0.7217 Recall: 0.5002\n",
      "F1: 0.5909 Duration: 46m 4s\n",
      "\n",
      "Validating...\n",
      "\n",
      "Progress: 100%\n",
      "\n",
      "Loss: 0.1209 Accuracy: 0.9581\n",
      "Precision: 0.7650 Recall: 0.6297\n",
      "F1: 0.6908 Duration: 4m 31s\n",
      "\n",
      "Epoch 2/6\n",
      "----------\n",
      "Training...\n",
      "\n",
      "Progress: 100%\n",
      "\n",
      "Loss: 0.1279 Accuracy: 0.9547\n",
      "Precision: 0.7373 Recall: 0.5772\n",
      "F1: 0.6475 Duration: 44m 44s\n",
      "\n",
      "Validating...\n",
      "\n",
      "Progress: 100%\n",
      "\n",
      "Loss: 0.1094 Accuracy: 0.9613\n",
      "Precision: 0.7567 Recall: 0.7072\n",
      "F1: 0.7311 Duration: 2m 52s\n",
      "\n",
      "Epoch 3/6\n",
      "----------\n",
      "Training...\n",
      "\n",
      "Progress: 100%\n",
      "\n",
      "Loss: 0.1283 Accuracy: 0.9553\n",
      "Precision: 0.7424 Recall: 0.5830\n",
      "F1: 0.6531 Duration: 43m 12s\n",
      "\n",
      "Validating...\n",
      "\n",
      "Progress: 100%\n",
      "\n",
      "Loss: 0.1204 Accuracy: 0.9585\n",
      "Precision: 0.7102 Recall: 0.7457\n",
      "F1: 0.7275 Duration: 3m 4s\n",
      "\n",
      "Epoch 4/6\n",
      "----------\n",
      "Training...\n",
      "\n",
      "Progress: 100%\n",
      "\n",
      "Loss: 0.1264 Accuracy: 0.9558\n",
      "Precision: 0.7433 Recall: 0.5921\n",
      "F1: 0.6592 Duration: 43m 28s\n",
      "\n",
      "Validating...\n",
      "\n",
      "Progress: 100%\n",
      "\n",
      "Loss: 0.1260 Accuracy: 0.9571\n",
      "Precision: 0.7395 Recall: 0.6528\n",
      "F1: 0.6934 Duration: 3m 0s\n",
      "\n",
      "Epoch 5/6\n",
      "----------\n",
      "Training...\n",
      "\n",
      "Progress: 100%\n",
      "\n",
      "Loss: 0.1250 Accuracy: 0.9565\n",
      "Precision: 0.7478 Recall: 0.5988\n",
      "F1: 0.6650 Duration: 44m 18s\n",
      "\n",
      "Validating...\n",
      "\n",
      "Progress: 100%\n",
      "\n",
      "Loss: 0.1374 Accuracy: 0.9545\n",
      "Precision: 0.7132 Recall: 0.6483\n",
      "F1: 0.6792 Duration: 3m 9s\n",
      "\n",
      "Epoch 6/6\n",
      "----------\n",
      "Training...\n",
      "\n",
      "Progress: 100%\n",
      "\n",
      "Loss: 0.1257 Accuracy: 0.9565\n",
      "Precision: 0.7473 Recall: 0.6003\n",
      "F1: 0.6658 Duration: 43m 22s\n",
      "\n",
      "Validating...\n",
      "\n",
      "Progress: 100%\n",
      "\n",
      "Loss: 0.1180 Accuracy: 0.9609\n",
      "Precision: 0.7673 Recall: 0.6803\n",
      "F1: 0.7212 Duration: 3m 7s\n",
      "\n",
      "Training complete in 287m 57s\n",
      "Best f1: 0.731126\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 6\n",
    "\n",
    "model, logs = train_model.train_model(\n",
    "    model,\n",
    "    trainDataset,\n",
    "    valDataset,\n",
    "    device,\n",
    "    numberOfEpochs=n_epochs,\n",
    "    returnLogs=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model and logs\n",
    "\n",
    "It might be useful to save your model if you want to continue your work later, or use it for inference later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(logs[\"val\"]).to_csv(\"exp_transfer_learning_5_logs_val.csv\", index=False)\n",
    "pd.DataFrame(logs[\"train\"]).to_csv(\"exp_transfer_learning_5_logs_train.csv\", index=False)\n",
    "torch.save(model, 'exp_transfer_learning_5_model.pkl')  # saves model with architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model\n",
    "\n",
    "- Load model back from state_dict and perform test on testing set\n",
    "- Load test-set\n",
    "- Load training time logs of performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"exp_transfer_learning_5_model.pkl\")\n",
    "testDataset = utils.load_pickle(\"tmp_test_data_exp_transfer_learning_5.pkl\")\n",
    "logsTable = pd.read_csv(\"exp_transfer_learning_5_logs_val.csv\")\n",
    "y_hats, y_trues = eval_model.test_model(model, testDataset, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation set performance during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>true positives</th>\n",
       "      <th>true negatives</th>\n",
       "      <th>false positives</th>\n",
       "      <th>false negatives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>187.343715</td>\n",
       "      <td>0.695931</td>\n",
       "      <td>0.509810</td>\n",
       "      <td>0.068144</td>\n",
       "      <td>0.441384</td>\n",
       "      <td>0.118060</td>\n",
       "      <td>689</td>\n",
       "      <td>10017</td>\n",
       "      <td>9422</td>\n",
       "      <td>872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>271.170860</td>\n",
       "      <td>0.120881</td>\n",
       "      <td>0.958095</td>\n",
       "      <td>0.764981</td>\n",
       "      <td>0.629725</td>\n",
       "      <td>0.690794</td>\n",
       "      <td>983</td>\n",
       "      <td>19137</td>\n",
       "      <td>302</td>\n",
       "      <td>578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>171.535487</td>\n",
       "      <td>0.109356</td>\n",
       "      <td>0.961333</td>\n",
       "      <td>0.756683</td>\n",
       "      <td>0.707239</td>\n",
       "      <td>0.731126</td>\n",
       "      <td>1104</td>\n",
       "      <td>19084</td>\n",
       "      <td>355</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>183.650126</td>\n",
       "      <td>0.120381</td>\n",
       "      <td>0.958476</td>\n",
       "      <td>0.710189</td>\n",
       "      <td>0.745676</td>\n",
       "      <td>0.727500</td>\n",
       "      <td>1164</td>\n",
       "      <td>18964</td>\n",
       "      <td>475</td>\n",
       "      <td>397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>180.207290</td>\n",
       "      <td>0.125977</td>\n",
       "      <td>0.957095</td>\n",
       "      <td>0.739478</td>\n",
       "      <td>0.652787</td>\n",
       "      <td>0.693433</td>\n",
       "      <td>1019</td>\n",
       "      <td>19080</td>\n",
       "      <td>359</td>\n",
       "      <td>542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>188.540844</td>\n",
       "      <td>0.137415</td>\n",
       "      <td>0.954476</td>\n",
       "      <td>0.713178</td>\n",
       "      <td>0.648302</td>\n",
       "      <td>0.679195</td>\n",
       "      <td>1012</td>\n",
       "      <td>19032</td>\n",
       "      <td>407</td>\n",
       "      <td>549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>186.874344</td>\n",
       "      <td>0.118031</td>\n",
       "      <td>0.960905</td>\n",
       "      <td>0.767341</td>\n",
       "      <td>0.680333</td>\n",
       "      <td>0.721222</td>\n",
       "      <td>1062</td>\n",
       "      <td>19117</td>\n",
       "      <td>322</td>\n",
       "      <td>499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     duration      loss  accuracy  precision    recall        f1  \\\n",
       "0  187.343715  0.695931  0.509810   0.068144  0.441384  0.118060   \n",
       "1  271.170860  0.120881  0.958095   0.764981  0.629725  0.690794   \n",
       "2  171.535487  0.109356  0.961333   0.756683  0.707239  0.731126   \n",
       "3  183.650126  0.120381  0.958476   0.710189  0.745676  0.727500   \n",
       "4  180.207290  0.125977  0.957095   0.739478  0.652787  0.693433   \n",
       "5  188.540844  0.137415  0.954476   0.713178  0.648302  0.679195   \n",
       "6  186.874344  0.118031  0.960905   0.767341  0.680333  0.721222   \n",
       "\n",
       "   true positives  true negatives  false positives  false negatives  \n",
       "0             689           10017             9422              872  \n",
       "1             983           19137              302              578  \n",
       "2            1104           19084              355              457  \n",
       "3            1164           18964              475              397  \n",
       "4            1019           19080              359              542  \n",
       "5            1012           19032              407              549  \n",
       "6            1062           19117              322              499  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logsTable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing set performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing set results.\n",
      " Accuracy\t0.959\n",
      " Precision\t0.716\n",
      " Recall \t0.705\n",
      " F1-score\t0.71\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing set results.\")\n",
    "print(f\" Accuracy\\t{round(eval_model.get_metric(y_trues, y_hats, 'accuracy'), 3)}\")\n",
    "print(f\" Precision\\t{round(eval_model.get_metric(y_trues, y_hats, 'precision'), 3)}\")\n",
    "print(f\" Recall \\t{round(eval_model.get_metric(y_trues, y_hats, 'recall'), 3)}\")\n",
    "print(f\" F1-score\\t{round(eval_model.get_metric(y_trues, y_hats, 'f1'), 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction analysis\n",
    "\n",
    "- How many positives and negatives has been predicted.\n",
    "  - Tuples like: **(label, count)**\n",
    "- Binary confusion matrix for each label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 19493), (1, 1507)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(*np.unique(y_hats, return_counts=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "\n",
    "label_names = [\"clouds\", \"male\", \"bird\", \"dog\", \"river\", \"portrait\", \"baby\", \"night\", \"people\", \"female\", \"sea\", \"tree\", \"car\", \"flower\"]\n",
    "results = multilabel_confusion_matrix(y_trues, y_hats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tRecall\tPrecision\n",
      "clouds\t0.649\t0.568\n",
      "male\t0.505\t0.635\n",
      "bird\t0.741\t0.87\n",
      "dog\t0.925\t0.507\n",
      "river\t0.0\tnan\n",
      "portra\t0.74\t0.778\n",
      "baby\t0.0\tnan\n",
      "night\t0.649\t0.324\n",
      "people\t0.824\t0.867\n",
      "female\t0.658\t0.69\n",
      "sea\t0.6\t0.571\n",
      "tree\t0.765\t0.553\n",
      "car\t0.722\t0.867\n",
      "flower\t0.684\t0.722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kasperireinikainen/env3.6/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "print(\"\\tRecall\\tPrecision\")\n",
    "for i, conf_mtx in enumerate(results):\n",
    "    tp = conf_mtx[1, 1]\n",
    "    tn = conf_mtx[0, 0]\n",
    "    fp = conf_mtx[0, 1]\n",
    "    fn = conf_mtx[1, 0]\n",
    "    recall = tp/(tp+fn)\n",
    "    precision = tp/(tp+fp)\n",
    "    print(f\"{label_names[i][:6]}\\t{round(recall, 3)}\\t{round(precision, 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download test set\n",
    "\n",
    "The testset will be made available during the last week before the deadline and can be downloaded in the same way as the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict for test set\n",
    "\n",
    "You should return your predictions for the test set in a plain text file.  The text file contains one row for each test set image.  Each row contains a binary prediction for each label (separated by a single space), 1 if it's present in the image, and 0 if not. The order of the labels is as follows (alphabetic order of the label names):\n",
    "\n",
    "    baby bird car clouds dog female flower male night people portrait river sea tree\n",
    "\n",
    "An example row could like like this if your system predicts the presense of a bird and clouds:\n",
    "\n",
    "    0 1 0 1 0 0 0 0 0 0 0 0 0 0\n",
    "    \n",
    "The order of the rows should be according to the numeric order of the image numbers.  In the test set, this means that the first row refers to image `im20001.jpg`, the second to `im20002.jpg`, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have the prediction output matrix prepared in `y` you can use the following function to save it to a text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-475fae65c704>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavetxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'results.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfmt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'%d'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "np.savetxt('results.txt', y, fmt='%d')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
