{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA20001 Deep Learning - Group Project\n",
    "## Image project\n",
    "\n",
    "- Testing [densenet201](https://pytorch.org/docs/stable/torchvision/models.html#id16) implementation of pretrained transfer learning models\n",
    "- Data preprocessing includes data augmentation, shuffle and split train=17k, val=1.5k, test=1.5k\n",
    "- Data augmentation IS applied\n",
    "- No data balancing applied\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# automatically reload dependencies and repository content so that kernel need not be restarted\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dependencies and select correct device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import train_model\n",
    "import eval_model\n",
    "import utils\n",
    "from image_dataset import ImageDataset\n",
    "from data_augmentation import DataAugmentation\n",
    "\n",
    "import time\n",
    "import torch\n",
    "from torchvision import models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    }
   ],
   "source": [
    "device = None\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Using GPU\")\n",
    "    device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    print(\"Using CPU\")\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define datasets\n",
    "\n",
    "- shuffle\n",
    "- train: 17k\n",
    "- valid: 1.5k\n",
    "- test: 1.5k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving test dataset temporarily so test can be performed after restarting kernel.\n",
      "# Train: 17000\n",
      "# Valid: 1500\n",
      "# Test: 1500\n"
     ]
    }
   ],
   "source": [
    "mapping_file = \"file_to_labels_table.csv\"\n",
    "df = pd.read_csv(mapping_file)\n",
    "train_idx, val_idx = utils.get_train_val_indexes(df, 0.85, shuffle=True)\n",
    "val_test_split_idx = int(val_idx.shape[0]*.5)\n",
    "test_idx = val_idx[:val_test_split_idx]\n",
    "val_idx = val_idx[val_test_split_idx:]\n",
    "\n",
    "dataAugmentation = DataAugmentation()\n",
    "trainDataset = ImageDataset(train_idx, dataAugmentation=dataAugmentation)\n",
    "valDataset = ImageDataset(val_idx)\n",
    "testDataset = ImageDataset(test_idx)\n",
    "\n",
    "print(\"Saving test dataset temporarily so test can be performed after restarting kernel.\")\n",
    "utils.save_pickle(testDataset, \"tmp_test_data_exp_transfer_learning_6.pkl\")\n",
    "print(\"# Train:\", len(trainDataset))\n",
    "print(\"# Valid:\", len(valDataset))\n",
    "print(\"# Test:\", len(testDataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model architecture\n",
    "\n",
    "The initial transfer learning implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "preTrainedModel = models.densenet201(pretrained=True)\n",
    "\n",
    "for param in preTrainedModel.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "num_ftrs = preTrainedModel.classifier.in_features\n",
    "num_classes = 14\n",
    "\n",
    "preTrainedModel.classifier = torch.nn.Sequential(\n",
    "    torch.nn.Linear(num_ftrs, num_classes),\n",
    "    torch.nn.Sigmoid()\n",
    ")\n",
    "\n",
    "model = preTrainedModel.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define test case\n",
    "\n",
    "Hyperparam search could be defined here. No hyperparam searches in this notebook as purpose of this test is to test the effect of data preprocessing technique on initial transfer learning model architecture and see how longer run on epochs affect loss.\n",
    "\n",
    "**Test objective**:\n",
    "\n",
    "- Testing [densenet201](https://pytorch.org/docs/stable/torchvision/models.html#id16) implementation of pretrained transfer learning models\n",
    "- Data preprocessing includes \n",
    "  - data augmentation, \n",
    "  - shuffle \n",
    "  - split train=17k, val=1.5k, test=1.5k\n",
    "\n",
    "\n",
    "**Training results**:\n",
    "\n",
    "- ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/6\n",
      "----------\n",
      "Validating...\n",
      "\n",
      "Progress: 100%\n",
      "\n",
      "Loss: 0.7370 Accuracy: 0.4297\n",
      "Precision: 0.0760 Recall: 0.6313\n",
      "F1: 0.1357 Duration: 1m 8s\n",
      "\n",
      "Epoch 1/6\n",
      "----------\n",
      "Training...\n",
      "\n",
      "Progress: 100%\n",
      "\n",
      "Loss: 0.1466 Accuracy: 0.9467\n",
      "Precision: 0.7147 Recall: 0.4341\n",
      "F1: 0.5401 Duration: 17m 46s\n",
      "\n",
      "Validating...\n",
      "\n",
      "Progress: 100%\n",
      "\n",
      "Loss: 0.1177 Accuracy: 0.9556\n",
      "Precision: 0.6633 Recall: 0.7596\n",
      "F1: 0.7082 Duration: 1m 2s\n",
      "\n",
      "Epoch 2/6\n",
      "----------\n",
      "Training...\n",
      "\n",
      "Progress: 100%\n",
      "\n",
      "Loss: 0.1334 Accuracy: 0.9512\n",
      "Precision: 0.7278 Recall: 0.5179\n",
      "F1: 0.6052 Duration: 13m 50s\n",
      "\n",
      "Validating...\n",
      "\n",
      "Progress: 100%\n",
      "\n",
      "Loss: 0.1226 Accuracy: 0.9540\n",
      "Precision: 0.6575 Recall: 0.7347\n",
      "F1: 0.6939 Duration: 1m 8s\n",
      "\n",
      "Epoch 3/6\n",
      "----------\n",
      "Training...\n",
      "\n",
      "Progress: 100%\n",
      "\n",
      "Loss: 0.1306 Accuracy: 0.9525\n",
      "Precision: 0.7310 Recall: 0.5398\n",
      "F1: 0.6210 Duration: 16m 10s\n",
      "\n",
      "Validating...\n",
      "\n",
      "Progress: 100%\n",
      "\n",
      "Loss: 0.1233 Accuracy: 0.9544\n",
      "Precision: 0.6736 Recall: 0.6917\n",
      "F1: 0.6826 Duration: 1m 6s\n",
      "\n",
      "Epoch 4/6\n",
      "----------\n",
      "Training...\n",
      "\n",
      "Progress: 100%\n",
      "\n",
      "Loss: 0.1316 Accuracy: 0.9523\n",
      "Precision: 0.7266 Recall: 0.5433\n",
      "F1: 0.6217 Duration: 16m 9s\n",
      "\n",
      "Validating...\n",
      "\n",
      "Progress: 100%\n",
      "\n",
      "Loss: 0.1272 Accuracy: 0.9524\n",
      "Precision: 0.6346 Recall: 0.7743\n",
      "F1: 0.6975 Duration: 1m 18s\n",
      "\n",
      "Epoch 5/6\n",
      "----------\n",
      "Training...\n",
      "\n",
      "Progress: 100%\n",
      "\n",
      "Loss: 0.1303 Accuracy: 0.9526\n",
      "Precision: 0.7285 Recall: 0.5463\n",
      "F1: 0.6244 Duration: 16m 26s\n",
      "\n",
      "Validating...\n",
      "\n",
      "Progress: 100%\n",
      "\n",
      "Loss: 0.1104 Accuracy: 0.9597\n",
      "Precision: 0.7016 Recall: 0.7515\n",
      "F1: 0.7257 Duration: 1m 22s\n",
      "\n",
      "Epoch 6/6\n",
      "----------\n",
      "Training...\n",
      "\n",
      "Progress: 100%\n",
      "\n",
      "Loss: 0.1295 Accuracy: 0.9525\n",
      "Precision: 0.7284 Recall: 0.5454\n",
      "F1: 0.6237 Duration: 16m 25s\n",
      "\n",
      "Validating...\n",
      "\n",
      "Progress: 100%\n",
      "\n",
      "Loss: 0.1084 Accuracy: 0.9613\n",
      "Precision: 0.7284 Recall: 0.7240\n",
      "F1: 0.7262 Duration: 1m 2s\n",
      "\n",
      "Training complete in 104m 52s\n",
      "Best f1: 0.726170\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 6\n",
    "\n",
    "model, logs = train_model.train_model(\n",
    "    model,\n",
    "    trainDataset,\n",
    "    valDataset,\n",
    "    device,\n",
    "    numberOfEpochs=n_epochs,\n",
    "    returnLogs=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model and logs\n",
    "\n",
    "It might be useful to save your model if you want to continue your work later, or use it for inference later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(logs[\"val\"]).to_csv(\"exp_transfer_learning_6_logs_val.csv\", index=False)\n",
    "pd.DataFrame(logs[\"train\"]).to_csv(\"exp_transfer_learning_6_logs_train.csv\", index=False)\n",
    "torch.save(model, 'exp_transfer_learning_6_model.pkl')  # saves model with architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model\n",
    "\n",
    "- Load model back from state_dict and perform test on testing set\n",
    "- Load test-set\n",
    "- Load training time logs of performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"exp_transfer_learning_6_model.pkl\")\n",
    "testDataset = utils.load_pickle(\"tmp_test_data_exp_transfer_learning_6.pkl\")\n",
    "logsTable = pd.read_csv(\"exp_transfer_learning_6_logs_val.csv\")\n",
    "y_hats, y_trues = eval_model.test_model(model, testDataset, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation set performance during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>true positives</th>\n",
       "      <th>true negatives</th>\n",
       "      <th>false positives</th>\n",
       "      <th>false negatives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68.463634</td>\n",
       "      <td>0.736977</td>\n",
       "      <td>0.429667</td>\n",
       "      <td>0.076003</td>\n",
       "      <td>0.631296</td>\n",
       "      <td>0.135672</td>\n",
       "      <td>940</td>\n",
       "      <td>8083</td>\n",
       "      <td>11428</td>\n",
       "      <td>549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61.664144</td>\n",
       "      <td>0.117738</td>\n",
       "      <td>0.955619</td>\n",
       "      <td>0.663343</td>\n",
       "      <td>0.759570</td>\n",
       "      <td>0.708203</td>\n",
       "      <td>1131</td>\n",
       "      <td>18937</td>\n",
       "      <td>574</td>\n",
       "      <td>358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67.916258</td>\n",
       "      <td>0.122640</td>\n",
       "      <td>0.954048</td>\n",
       "      <td>0.657452</td>\n",
       "      <td>0.734721</td>\n",
       "      <td>0.693942</td>\n",
       "      <td>1094</td>\n",
       "      <td>18941</td>\n",
       "      <td>570</td>\n",
       "      <td>395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65.846471</td>\n",
       "      <td>0.123268</td>\n",
       "      <td>0.954381</td>\n",
       "      <td>0.673643</td>\n",
       "      <td>0.691739</td>\n",
       "      <td>0.682571</td>\n",
       "      <td>1030</td>\n",
       "      <td>19012</td>\n",
       "      <td>499</td>\n",
       "      <td>459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>77.996974</td>\n",
       "      <td>0.127152</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.634562</td>\n",
       "      <td>0.774345</td>\n",
       "      <td>0.697520</td>\n",
       "      <td>1153</td>\n",
       "      <td>18847</td>\n",
       "      <td>664</td>\n",
       "      <td>336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>81.774200</td>\n",
       "      <td>0.110411</td>\n",
       "      <td>0.959714</td>\n",
       "      <td>0.701567</td>\n",
       "      <td>0.751511</td>\n",
       "      <td>0.725681</td>\n",
       "      <td>1119</td>\n",
       "      <td>19035</td>\n",
       "      <td>476</td>\n",
       "      <td>370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>61.912110</td>\n",
       "      <td>0.108371</td>\n",
       "      <td>0.961286</td>\n",
       "      <td>0.728378</td>\n",
       "      <td>0.723976</td>\n",
       "      <td>0.726170</td>\n",
       "      <td>1078</td>\n",
       "      <td>19109</td>\n",
       "      <td>402</td>\n",
       "      <td>411</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    duration      loss  accuracy  precision    recall        f1  \\\n",
       "0  68.463634  0.736977  0.429667   0.076003  0.631296  0.135672   \n",
       "1  61.664144  0.117738  0.955619   0.663343  0.759570  0.708203   \n",
       "2  67.916258  0.122640  0.954048   0.657452  0.734721  0.693942   \n",
       "3  65.846471  0.123268  0.954381   0.673643  0.691739  0.682571   \n",
       "4  77.996974  0.127152  0.952381   0.634562  0.774345  0.697520   \n",
       "5  81.774200  0.110411  0.959714   0.701567  0.751511  0.725681   \n",
       "6  61.912110  0.108371  0.961286   0.728378  0.723976  0.726170   \n",
       "\n",
       "   true positives  true negatives  false positives  false negatives  \n",
       "0             940            8083            11428              549  \n",
       "1            1131           18937              574              358  \n",
       "2            1094           18941              570              395  \n",
       "3            1030           19012              499              459  \n",
       "4            1153           18847              664              336  \n",
       "5            1119           19035              476              370  \n",
       "6            1078           19109              402              411  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logsTable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing set performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing set results.\n",
      " Accuracy\t0.957\n",
      " Precision\t0.703\n",
      " Recall \t0.724\n",
      " F1-score\t0.713\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing set results.\")\n",
    "print(f\" Accuracy\\t{round(eval_model.get_metric(y_trues, y_hats, 'accuracy'), 3)}\")\n",
    "print(f\" Precision\\t{round(eval_model.get_metric(y_trues, y_hats, 'precision'), 3)}\")\n",
    "print(f\" Recall \\t{round(eval_model.get_metric(y_trues, y_hats, 'recall'), 3)}\")\n",
    "print(f\" F1-score\\t{round(eval_model.get_metric(y_trues, y_hats, 'f1'), 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra analysis\n",
    "\n",
    "How many positives and negatives has been predicted.\n",
    "\n",
    "Tuples like: **(label, count)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 19393), (1, 1607)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(*np.unique(y_hats, return_counts=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download test set\n",
    "\n",
    "The testset will be made available during the last week before the deadline and can be downloaded in the same way as the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict for test set\n",
    "\n",
    "You should return your predictions for the test set in a plain text file.  The text file contains one row for each test set image.  Each row contains a binary prediction for each label (separated by a single space), 1 if it's present in the image, and 0 if not. The order of the labels is as follows (alphabetic order of the label names):\n",
    "\n",
    "    baby bird car clouds dog female flower male night people portrait river sea tree\n",
    "\n",
    "An example row could like like this if your system predicts the presense of a bird and clouds:\n",
    "\n",
    "    0 1 0 1 0 0 0 0 0 0 0 0 0 0\n",
    "    \n",
    "The order of the rows should be according to the numeric order of the image numbers.  In the test set, this means that the first row refers to image `im20001.jpg`, the second to `im20002.jpg`, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have the prediction output matrix prepared in `y` you can use the following function to save it to a text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('results.txt', y, fmt='%d')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
