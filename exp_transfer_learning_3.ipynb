{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA20001 Deep Learning - Group Project\n",
    "## Image project\n",
    "\n",
    "**Due Thursday, May 22, before 23:59.**\n",
    "\n",
    "- Testing first implementation of [resnext50_32x4d](https://pytorch.org/docs/stable/torchvision/models.html#id27) pretrained transfer learning model\n",
    "- Data has the most straightforward preprocessing steps with shuffle and split train=17k, val=1.5k, test=1.5k\n",
    "- Data augmentation IS applied\n",
    "- Data balancing IS applied\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# automatically reload dependencies and repository content so that kernel need not be restarted\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dependencies and select correct device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import train_model\n",
    "import eval_model\n",
    "import utils\n",
    "from image_dataset import ImageDataset\n",
    "from data_augmentation import DataAugmentation\n",
    "from data_balancer import DataBalancer\n",
    "\n",
    "import time\n",
    "import torch\n",
    "from torchvision import models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n"
     ]
    }
   ],
   "source": [
    "device = None\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Using GPU\")\n",
    "    device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    print(\"Using CPU\")\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define datasets\n",
    "\n",
    "- augmentation\n",
    "- balancing\n",
    "- train: 17k\n",
    "- valid: 1.5k\n",
    "- test: 1.5k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving test dataset temporarily so test can be performed after restarting kernel.\n",
      "# Train: 80000\n",
      "# Valid: 1500\n",
      "# Test: 1500\n"
     ]
    }
   ],
   "source": [
    "mapping_file = \"file_to_labels_table.csv\"\n",
    "df = pd.read_csv(mapping_file)\n",
    "train_idx, val_idx = utils.get_train_val_indexes(df, 0.85, shuffle=False)\n",
    "val_test_split_idx = int(val_idx.shape[0]*.5)\n",
    "test_idx = val_idx[:val_test_split_idx]\n",
    "val_idx = val_idx[val_test_split_idx:]\n",
    "\n",
    "dataAugmentation = DataAugmentation()\n",
    "dataBalancer = DataBalancer()\n",
    "trainIds = dataBalancer.balanceData(range(1,17001), 80000-17000, range(1,17001))\n",
    "trainDataset = ImageDataset(trainIds, dataAugmentation=dataAugmentation)\n",
    "valDataset = ImageDataset(val_idx, dataAugmentation=dataAugmentation)\n",
    "testDataset = ImageDataset(test_idx, dataAugmentation=dataAugmentation)\n",
    "\n",
    "print(\"Saving test dataset temporarily so test can be performed after restarting kernel.\")\n",
    "utils.save_pickle(testDataset, \"tmp_test_data_exp_transfer_learning_3.pkl\")\n",
    "print(\"# Train:\", len(trainDataset))\n",
    "print(\"# Valid:\", len(valDataset))\n",
    "print(\"# Test:\", len(testDataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correction to val and test sets to prevent them from overlapping with train set\n",
    "valDataset = ImageDataset(range(17000, 18500), dataAugmentation=dataAugmentation)\n",
    "testDataset = ImageDataset(range(18500, 20000), dataAugmentation=dataAugmentation)\n",
    "print(\"Saving test dataset temporarily so test can be performed after restarting kernel.\")\n",
    "utils.save_pickle(testDataset, \"tmp_test_data_exp_transfer_learning_3.pkl\")\n",
    "print(\"# Valid:\", len(valDataset))\n",
    "print(\"# Test:\", len(testDataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model architecture\n",
    "\n",
    "The initial transfer learning implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "preTrainedModel = models.resnext50_32x4d(pretrained=True)\n",
    "\n",
    "for param in preTrainedModel.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "num_ftrs = preTrainedModel.fc.in_features\n",
    "num_classes = 14\n",
    "\n",
    "preTrainedModel.fc = torch.nn.Sequential(\n",
    "    torch.nn.Linear(num_ftrs, num_classes),\n",
    "    torch.nn.Sigmoid()\n",
    ")\n",
    "\n",
    "model = preTrainedModel.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define test case\n",
    "\n",
    "Hyperparam search could be defined here. No hyperparam searches in this notebook as purpose of this test is to test the effect of data preprocessing technique on initial transfer learning model architecture and see if balanced dataset is better than more epochs.\n",
    "\n",
    "**Test objective**:\n",
    "\n",
    "- Testing first implementation of [resnext50_32x4d](https://pytorch.org/docs/stable/torchvision/models.html#id27) pretrained transfer learning model\n",
    "- Data has the most straightforward preprocessing steps with shuffle and split train=17k, val=1.5k, test=1.5k\n",
    "- Data augmentation IS applied\n",
    "- Data balancing IS applied\n",
    "\n",
    "**Training results**:\n",
    "\n",
    "- Training job ran over 19.5 taking ~25 hours\n",
    "- The job ran on the background and jupyter client was not connected the whole time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 6\n",
    "\n",
    "model, logs = train_model.train_model(\n",
    "    model,\n",
    "    trainDataset,\n",
    "    valDataset,\n",
    "    device,\n",
    "    numberOfEpochs=n_epochs,\n",
    "    return_logs=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model and logs\n",
    "\n",
    "It might be useful to save your model if you want to continue your work later, or use it for inference later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(logs).to_csv(\"exp_transfer_learning_3_logs.csv\", index=False)\n",
    "torch.save(model.state_dict(), 'exp_transfer_learning_3_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model\n",
    "\n",
    "- Load model back from state_dict and perform test on testing set\n",
    "- Load test-set\n",
    "- Load training time logs of performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"exp_transfer_learning_3_model.pkl\"))\n",
    "testDataset = utils.load_pickle(\"tmp_test_data_exp_transfer_learning_3.pkl\")\n",
    "train_logs = pd.read_csv(\"exp_transfer_learning_3_logs.csv\")\n",
    "y_hats, y_trues = eval_model.test_model(model, testDataset, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation set performance during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tensor(0.9354, dtype=torch.float64)</td>\n",
       "      <td>0.187078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>tensor(0.9333, dtype=torch.float64)</td>\n",
       "      <td>0.194943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>tensor(0.9323, dtype=torch.float64)</td>\n",
       "      <td>0.194268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>tensor(0.9364, dtype=torch.float64)</td>\n",
       "      <td>0.188344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>tensor(0.9322, dtype=torch.float64)</td>\n",
       "      <td>0.200083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>tensor(0.9330, dtype=torch.float64)</td>\n",
       "      <td>0.192452</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch                             accuracy      loss\n",
       "0      0  tensor(0.9354, dtype=torch.float64)  0.187078\n",
       "1      1  tensor(0.9333, dtype=torch.float64)  0.194943\n",
       "2      2  tensor(0.9323, dtype=torch.float64)  0.194268\n",
       "3      3  tensor(0.9364, dtype=torch.float64)  0.188344\n",
       "4      4  tensor(0.9322, dtype=torch.float64)  0.200083\n",
       "5      5  tensor(0.9330, dtype=torch.float64)  0.192452"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing set performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing set results.\n",
      " Accuracy\t0.937\n",
      " Precision\t0.546\n",
      " Recall \t0.716\n",
      " F1-score\t0.62\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing set results.\")\n",
    "print(f\" Accuracy\\t{round(eval_model.get_metric(y_trues, y_hats, 'accuracy'), 3)}\")\n",
    "print(f\" Precision\\t{round(eval_model.get_metric(y_trues, y_hats, 'precision'), 3)}\")\n",
    "print(f\" Recall \\t{round(eval_model.get_metric(y_trues, y_hats, 'recall'), 3)}\")\n",
    "print(f\" F1-score\\t{round(eval_model.get_metric(y_trues, y_hats, 'f1'), 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra analysis\n",
    "\n",
    "Results above seems like most of the predictions are ones.\n",
    "\n",
    "Tuples like: **(label, count)**\n",
    "\n",
    "Result:\n",
    "Seems like instead of giving too many ones, it is just way too selective with them for which reason the total number of positive predictions is very low but are quite accurate..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 19025), (1, 1975)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(*np.unique(y_hats, return_counts=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download test set\n",
    "\n",
    "The testset will be made available during the last week before the deadline and can be downloaded in the same way as the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict for test set\n",
    "\n",
    "You should return your predictions for the test set in a plain text file.  The text file contains one row for each test set image.  Each row contains a binary prediction for each label (separated by a single space), 1 if it's present in the image, and 0 if not. The order of the labels is as follows (alphabetic order of the label names):\n",
    "\n",
    "    baby bird car clouds dog female flower male night people portrait river sea tree\n",
    "\n",
    "An example row could like like this if your system predicts the presense of a bird and clouds:\n",
    "\n",
    "    0 1 0 1 0 0 0 0 0 0 0 0 0 0\n",
    "    \n",
    "The order of the rows should be according to the numeric order of the image numbers.  In the test set, this means that the first row refers to image `im20001.jpg`, the second to `im20002.jpg`, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have the prediction output matrix prepared in `y` you can use the following function to save it to a text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('results.txt', y, fmt='%d')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
