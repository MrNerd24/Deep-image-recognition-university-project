{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA20001 Deep Learning - Group Project\n",
    "## Image project\n",
    "\n",
    "21/05/2020\n",
    "- Testing second implementation of [resnext50_32x4d](https://pytorch.org/docs/stable/torchvision/models.html#id27) implementation of pretrained transfer learning models\n",
    "  - New addition: hidden fully-connected layer with 256 nodes\n",
    "- Data preprocessing includes: (same preprocessing steps as exp_transfer_learning_2.ipynb)\n",
    "  - shuffle\n",
    "  - split: train=17k, val=1.5k, test=1.5k\n",
    "  - data augmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# automatically reload dependencies and repository content so that kernel need not be restarted\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dependencies and select correct device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import train_model\n",
    "import eval_model\n",
    "import utils\n",
    "from image_dataset import ImageDataset\n",
    "from data_augmentation import DataAugmentation\n",
    "\n",
    "import time\n",
    "import torch\n",
    "from torchvision import models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n"
     ]
    }
   ],
   "source": [
    "device = None\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Using GPU\")\n",
    "    device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    print(\"Using CPU\")\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define datasets\n",
    "\n",
    "- shuffle\n",
    "- train: 17k\n",
    "- valid: 1.5k\n",
    "- test: 1.5k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving test dataset temporarily so test can be performed after restarting kernel.\n",
      "# Train: 17000\n",
      "# Valid: 1500\n",
      "# Test: 1500\n"
     ]
    }
   ],
   "source": [
    "mapping_file = \"file_to_labels_table.csv\"\n",
    "df = pd.read_csv(mapping_file)\n",
    "train_idx, val_idx = utils.get_train_val_indexes(df, 0.85, shuffle=True)\n",
    "val_test_split_idx = int(val_idx.shape[0]*.5)\n",
    "test_idx = val_idx[:val_test_split_idx]\n",
    "val_idx = val_idx[val_test_split_idx:]\n",
    "\n",
    "dataAugmentation = DataAugmentation()\n",
    "trainDataset = ImageDataset(train_idx, dataAugmentation=dataAugmentation)\n",
    "valDataset = ImageDataset(val_idx)\n",
    "testDataset = ImageDataset(test_idx)\n",
    "\n",
    "print(\"Saving test dataset temporarily so test can be performed after restarting kernel.\")\n",
    "utils.save_pickle(testDataset, \"tmp_test_data_exp_transfer_learning_4.pkl\")\n",
    "print(\"# Train:\", len(trainDataset))\n",
    "print(\"# Valid:\", len(valDataset))\n",
    "print(\"# Test:\", len(testDataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model architecture\n",
    "\n",
    "The initial transfer learning implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "preTrainedModel = models.resnext50_32x4d(pretrained=True)\n",
    "\n",
    "for param in preTrainedModel.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "num_ftrs = preTrainedModel.fc.in_features\n",
    "num_classes = 14\n",
    "\n",
    "preTrainedModel.fc = torch.nn.Sequential(\n",
    "    torch.nn.Linear(num_ftrs, 256),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(256, num_classes),\n",
    "    torch.nn.Sigmoid()\n",
    ")\n",
    "\n",
    "model = preTrainedModel.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define test case\n",
    "\n",
    "Hyperparam search could be defined here. No hyperparam searches in this notebook as purpose of this test is to test the effect of data preprocessing technique on initial transfer learning model architecture and see how longer run on epochs affect loss.\n",
    "\n",
    "**Test objective**:\n",
    "\n",
    "- Testing second implementation of [resnext50_32x4d](https://pytorch.org/docs/stable/torchvision/models.html#id27) implementation of pretrained transfer learning models\n",
    "  - New addition: hidden fully-connected layer with 256 nodes\n",
    "- Data preprocessing includes data augmentation, shuffle and split train=17k, val=1.5k, test=1.5k\n",
    "- Data augmentation IS applied\n",
    "\n",
    "**Training results**:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "----------\n",
      "Training...\n",
      "\n",
      "Progress: 100%\n",
      "\n",
      "train Loss: 0.1549 Acc: 0.9435\n",
      "Validating...\n",
      "\n",
      "Progress: 100%\n",
      "\n",
      "val Loss: 0.1101 Acc: 0.9579\n",
      "\n",
      "Epoch 2/5\n",
      "----------\n",
      "Training...\n",
      "\n",
      "Progress: 100%\n",
      "\n",
      "train Loss: 0.1358 Acc: 0.9494\n",
      "Validating...\n",
      "\n",
      "Progress: 100%\n",
      "\n",
      "val Loss: 0.1138 Acc: 0.9565\n",
      "\n",
      "Epoch 3/5\n",
      "----------\n",
      "Training...\n",
      "\n",
      "Progress: 100%\n",
      "\n",
      "train Loss: 0.1320 Acc: 0.9511\n",
      "Validating...\n",
      "\n",
      "Progress: 100%\n",
      "\n",
      "val Loss: 0.1089 Acc: 0.9581\n",
      "\n",
      "Epoch 4/5\n",
      "----------\n",
      "Training...\n",
      "\n",
      "Progress: 100%\n",
      "\n",
      "train Loss: 0.1283 Acc: 0.9521\n",
      "Validating...\n",
      "\n",
      "Progress: 100%\n",
      "\n",
      "val Loss: 0.1076 Acc: 0.9597\n",
      "\n",
      "Epoch 5/5\n",
      "----------\n",
      "Training...\n",
      "\n",
      "Progress: 100%\n",
      "\n",
      "train Loss: 0.1266 Acc: 0.9528\n",
      "Validating...\n",
      "\n",
      "Progress: 100%\n",
      "\n",
      "val Loss: 0.1064 Acc: 0.9601\n",
      "\n",
      "Training complete in 109m 6s\n",
      "Best val Acc: 0.960143\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 5\n",
    "\n",
    "model, logs = train_model.train_model(\n",
    "    model,\n",
    "    trainDataset,\n",
    "    valDataset,\n",
    "    device,\n",
    "    numberOfEpochs=n_epochs,\n",
    "    return_logs=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model and logs\n",
    "\n",
    "It might be useful to save your model if you want to continue your work later, or use it for inference later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(logs).to_csv(\"exp_transfer_learning_4_logs.csv\", index=False)\n",
    "torch.save(model, 'exp_transfer_learning_4_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model\n",
    "\n",
    "- Load model back from state_dict and perform test on testing set\n",
    "- Load test-set\n",
    "- Load training time logs of performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"exp_transfer_learning_4_model.pkl\")\n",
    "testDataset = utils.load_pickle(\"tmp_test_data_exp_transfer_learning_4.pkl\")\n",
    "train_logs = pd.read_csv(\"exp_transfer_learning_4_logs.csv\")\n",
    "y_hats, y_trues = eval_model.test_model(model, testDataset, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation set performance during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epoch': [0, 1, 2, 3, 4],\n",
       " 'accuracy': [tensor(0.9579, dtype=torch.float64),\n",
       "  tensor(0.9565, dtype=torch.float64),\n",
       "  tensor(0.9581, dtype=torch.float64),\n",
       "  tensor(0.9597, dtype=torch.float64),\n",
       "  tensor(0.9601, dtype=torch.float64)],\n",
       " 'loss': [0.1101102386471771,\n",
       "  0.11380755911554609,\n",
       "  0.10892651088748659,\n",
       "  0.10757335066511517,\n",
       "  0.10641117515166601]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing set performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing set results.\n",
      " Accuracy\t0.959\n",
      " Precision\t0.745\n",
      " Recall \t0.688\n",
      " F1-score\t0.715\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing set results.\")\n",
    "print(f\" Accuracy\\t{round(eval_model.get_metric(y_trues, y_hats, 'accuracy'), 3)}\")\n",
    "print(f\" Precision\\t{round(eval_model.get_metric(y_trues, y_hats, 'precision'), 3)}\")\n",
    "print(f\" Recall \\t{round(eval_model.get_metric(y_trues, y_hats, 'recall'), 3)}\")\n",
    "print(f\" F1-score\\t{round(eval_model.get_metric(y_trues, y_hats, 'f1'), 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra analysis\n",
    "\n",
    "How many positives and negatives has been predicted.\n",
    "\n",
    "Tuples like: **(label, count)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 19592), (1, 1408)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(*np.unique(y_hats, return_counts=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download test set\n",
    "\n",
    "The testset will be made available during the last week before the deadline and can be downloaded in the same way as the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict for test set\n",
    "\n",
    "You should return your predictions for the test set in a plain text file.  The text file contains one row for each test set image.  Each row contains a binary prediction for each label (separated by a single space), 1 if it's present in the image, and 0 if not. The order of the labels is as follows (alphabetic order of the label names):\n",
    "\n",
    "    baby bird car clouds dog female flower male night people portrait river sea tree\n",
    "\n",
    "An example row could like like this if your system predicts the presense of a bird and clouds:\n",
    "\n",
    "    0 1 0 1 0 0 0 0 0 0 0 0 0 0\n",
    "    \n",
    "The order of the rows should be according to the numeric order of the image numbers.  In the test set, this means that the first row refers to image `im20001.jpg`, the second to `im20002.jpg`, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have the prediction output matrix prepared in `y` you can use the following function to save it to a text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('results.txt', y, fmt='%d')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
